{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXhjY9dGwJls"
      },
      "source": [
        "NOMBRES: Diego Alberto\n",
        "\n",
        "APELLIDOS: Leiva Pérez\n",
        "\n",
        "CARNE: 21752\n",
        "\n",
        "FECHA: 04/09/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilidades para Texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Convierte a minúsculas, elimina puntuación y caracteres especiales,\n",
        "    y normaliza espacios en blanco.\n",
        "    Args:\n",
        "        text (str): Texto a normalizar.\n",
        "    Returns:\n",
        "        str: Texto normalizado.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    # Conserva letras (incluye tildes/ñ), dígitos y espacios.\n",
        "    text = re.sub(r\"[^a-záéíóúüñ0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def tokenize(text: str):\n",
        "    \"\"\"\n",
        "    Tokeniza el texto normalizado en palabras.\n",
        "    Args:\n",
        "        text (str): Texto a tokenizar.\n",
        "    Returns:\n",
        "        list: Lista de tokens (palabras).\n",
        "    \"\"\"\n",
        "    return normalize_text(text).split()\n",
        "\n",
        "def build_vocab(tokenized_docs, min_freq: int = 1):\n",
        "    \"\"\"\n",
        "    Construye el vocabulario a partir de documentos tokenizados.\n",
        "    Args:\n",
        "        tokenized_docs (list): Lista de documentos tokenizados.\n",
        "        min_freq (int): Frecuencia mínima para incluir una palabra en el vocabulario.\n",
        "    Returns:\n",
        "        tuple: (vocabulario, word2idx, idx2word, counts)\n",
        "    \"\"\"\n",
        "    counts = Counter([t for doc in tokenized_docs for t in doc])\n",
        "    vocab = [w for w, c in counts.items() if c >= min_freq]\n",
        "    vocab = sorted(vocab)\n",
        "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "    idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "    return vocab, word2idx, idx2word, counts\n",
        "\n",
        "def sliding_windows_indices(center, window_size, n):\n",
        "    \"\"\"\n",
        "    Obtiene los índices de las palabras en una ventana deslizante alrededor de una palabra central.\n",
        "    Args:\n",
        "        center (int): Índice de la palabra central.\n",
        "        window_size (int): Tamaño de la ventana (número de palabras a cada lado).\n",
        "        n (int): Longitud total de la secuencia.\n",
        "    Returns:\n",
        "        list: Lista de índices en la ventana deslizante.\n",
        "    \"\"\"\n",
        "    start = max(0, center - window_size)\n",
        "    end = min(n, center + window_size + 1)\n",
        "    return [i for i in range(start, end) if i != center]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7nnvCPLh5Ms"
      },
      "source": [
        "## Ejercicio 1\n",
        "Cree un corpus a su gusto como el visto en clase, cálcule PPMI, pero aplicando Lapace Smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hf3GX1_liFXd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Docs: 20\n",
            "Vocab size: 68\n",
            "Top-10 más frecuentes: [('la', 30), ('el', 24), ('en', 16), ('y', 15), ('con', 13), ('joven', 13), ('mayor', 6), ('sala', 5), ('adulto', 5), ('adulta', 5)]\n"
          ]
        }
      ],
      "source": [
        "corpus_docs = [\n",
        "    # Abuelos/as y edad/actividad\n",
        "    \"el abuelo mayor juega ajedrez en la sala con la abuela mayor\",\n",
        "    \"la abuela mayor cuida el jardin y hace jardineria con el abuelo mayor\",\n",
        "    # Padres y madres + actividades\n",
        "    \"el padre adulto repara autos en el taller y aprende mecanica\",\n",
        "    \"la madre adulta estudia medicina y cuida la casa con paciencia\",\n",
        "    # Hijos/as + actividades/edad\n",
        "    \"el hijo joven practica skate en el parque despues de la escuela\",\n",
        "    \"la hija joven pinta cuadros y aprende pintura en la escuela\",\n",
        "    # Tios/as + actividades/edad\n",
        "    \"el tio adulto sale a pesca y conversa en la sala\",\n",
        "    \"la tia adulta baila danza y organiza reuniones en la casa\",\n",
        "    # Primos/as + actividades/edad\n",
        "    \"el primo joven juega videojuegos y estudia con el hijo joven\",\n",
        "    \"la prima joven hace fotografia y practica pintura con la hija joven\",\n",
        "    # Sobrinos/as + edad\n",
        "    \"el sobrino niño visita la casa y lee cuentos en la sala\",\n",
        "    \"la sobrina niña dibuja en el jardin y juega con la prima joven\",\n",
        "    # Conexiones cruzadas (refuerza co-ocurrencias)\n",
        "    \"el padre adulto conversa con el abuelo mayor en la sala\",\n",
        "    \"la madre adulta camina con la abuela mayor en el jardin\",\n",
        "    \"el tio adulto repara herramientas en el taller con el padre adulto\",\n",
        "    \"la tia adulta organiza danza en la escuela y ayuda a la madre adulta\",\n",
        "    \"el primo joven patina skate en el parque y habla con el sobrino niño\",\n",
        "    \"la prima joven toma fotografia en el jardin y pinta con la hija joven\",\n",
        "    \"el hijo joven visita la casa y estudia en la escuela con el primo joven\",\n",
        "    \"la hija joven practica pintura en la sala y conversa con la sobrina niña\",\n",
        "]\n",
        "\n",
        "# Preprocesamiento\n",
        "tokenized_docs = [tokenize(d) for d in corpus_docs] # Lista de listas de tokens\n",
        "vocab, word2idx, idx2word, counts = build_vocab(tokenized_docs, min_freq=1) # Vocabulario y mapeos\n",
        "\n",
        "# Estadísticas básicas\n",
        "print(\"Docs:\", len(tokenized_docs)) # Número de documentos\n",
        "print(\"Vocab size:\", len(vocab)) # Tamaño del vocabulario \n",
        "print(\"Top-10 más frecuentes:\", Counter([t for d in tokenized_docs for t in d]).most_common(10)) # Top-10 palabras más frecuentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matriz de co-ocurrencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_cooccurrence(tokenized_docs, word2idx, window_size=2):\n",
        "    \"\"\"\n",
        "    Construye la matriz de co-ocurrencias a partir de documentos tokenizados.\n",
        "    Args:\n",
        "        tokenized_docs (list): Lista de documentos tokenizados.\n",
        "        word2idx (dict): Mapeo de palabras a índices.\n",
        "        window_size (int): Tamaño de la ventana deslizante.\n",
        "    Returns:\n",
        "        np.ndarray: Matriz de co-ocurrencias.\n",
        "    \"\"\"\n",
        "    V = len(word2idx)\n",
        "    M = np.zeros((V, V), dtype=float)\n",
        "    for doc in tokenized_docs:\n",
        "        n = len(doc)\n",
        "        for i, w in enumerate(doc):\n",
        "            wi = word2idx[w]\n",
        "            for j in sliding_windows_indices(i, window_size, n):\n",
        "                cj = word2idx[doc[j]]\n",
        "                M[wi, cj] += 1.0\n",
        "    return M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WINDOW = 2 # Tamaño de la ventana deslizante\n",
        "C = build_cooccurrence(tokenized_docs, word2idx, window_size=WINDOW) # Matriz de co-ocurrencias\n",
        "cooc_df= pd.DataFrame(C,index=vocab,columns=vocab)\n",
        "cooc_df\n",
        "cooc_df.iloc[:15,:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PPMI con Laplace smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ppmi_laplace(C, alpha=1.0, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Calcula la matriz PPMI con suavizado de Laplace a partir de la matriz de co-ocurrencias.\n",
        "    Args:\n",
        "        C (np.ndarray): Matriz de co-ocurrencias.\n",
        "        alpha (float): Parámetro de suavizado de Laplace.\n",
        "        eps (float): Pequeña constante para evitar log(0).\n",
        "    Returns:\n",
        "        np.ndarray: Matriz PPMI.\n",
        "    \"\"\"\n",
        "    C_s = C + alpha\n",
        "    total = float(C_s.sum()) + eps\n",
        "    Pwc = C_s / total\n",
        "    Pw = Pwc.sum(axis=1, keepdims=True)\n",
        "    Pc = Pwc.sum(axis=0, keepdims=True)\n",
        "    PMI = np.log((Pwc + eps) / (Pw @ Pc + eps))\n",
        "    return np.maximum(PMI, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PPMI = ppmi_laplace(C, alpha=1.0)\n",
        "ppmi_df = pd.DataFrame(PPMI, index=vocab, columns=vocab)\n",
        "ppmi_df.iloc[:15,:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Similitud coseno y vecinos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity_matrix(X):\n",
        "    \"\"\"\n",
        "    Calcula la matriz de similitud coseno entre vectores.\n",
        "    Args:\n",
        "        X (np.ndarray): Matriz de vectores (filas).\n",
        "    Returns:\n",
        "        np.ndarray: Matriz de similitud coseno.\n",
        "    \"\"\"\n",
        "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
        "    Xn = X / norms\n",
        "    return Xn @ Xn.T\n",
        "\n",
        "def top_k_neighbors(word, vocab, simM, k=5):\n",
        "    \"\"\"\n",
        "    Obtiene los k vecinos más similares a una palabra dada usando la matriz de similitud.\n",
        "    Args:\n",
        "        word (str): Palabra objetivo.\n",
        "        vocab (list): Lista de palabras en el vocabulario.\n",
        "        simM (np.ndarray): Matriz de similitud coseno.\n",
        "        k (int): Número de vecinos a retornar.\n",
        "    Returns:\n",
        "        list: Lista de tuplas (palabra, similitud) de los k vecinos más similares.\n",
        "    \"\"\"\n",
        "    if word not in vocab:\n",
        "        return []\n",
        "    i = vocab.index(word)\n",
        "    row = simM[i].copy()\n",
        "    row[i] = -np.inf\n",
        "    idxs = np.argsort(-row)[:k]\n",
        "    return [(vocab[j], float(row[j])) for j in idxs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vecinos de 'abuelo':  [('ajedrez', 0.7109079885356765), ('abuela', 0.6976531467722968), ('primo', 0.38374778539786536), ('el', 0.3705223697033903), ('taller', 0.3563502231480342)]\n",
            "\n",
            "Vecinos de 'abuela':  [('abuelo', 0.6976531467722968), ('ajedrez', 0.4651875271077593), ('el', 0.37895899812793693), ('la', 0.31028366322642953), ('casa', 0.3036681735682681)]\n",
            "\n",
            "Vecinos de 'padre':  [('tio', 0.7892677832909435), ('autos', 0.7449253318807908), ('herramientas', 0.7449253318807908), ('repara', 0.39727140826978463), ('adulto', 0.39719233605564175)]\n",
            "\n",
            "Vecinos de 'madre':  [('medicina', 0.5527642350179169), ('tia', 0.5521042664651762), ('camina', 0.4372385644552799), ('danza', 0.4119719612679356), ('baila', 0.3522734556288305)]\n",
            "\n",
            "Vecinos de 'hijo':  [('skate', 0.6647841962384234), ('primo', 0.6495612619961113), ('hija', 0.6098242549105677), ('fotografia', 0.516092307836903), ('prima', 0.44078930388764637)]\n",
            "\n",
            "Vecinos de 'hija':  [('prima', 0.6594140714460223), ('hijo', 0.6098242549105677), ('pintura', 0.5180694707375006), ('skate', 0.49791492040856805), ('fotografia', 0.4954482720942392)]\n",
            "\n",
            "Vecinos de 'tio':  [('autos', 0.806600585613004), ('herramientas', 0.806600585613004), ('padre', 0.7892677832909435), ('a', 0.46480769839314606), ('adulto', 0.43705455627639106)]\n",
            "\n",
            "Vecinos de 'tia':  [('danza', 0.9414629001773921), ('madre', 0.5521042664651762), ('reuniones', 0.49234030518162347), ('camina', 0.45858869269000124), ('medicina', 0.3837507729535016)]\n",
            "\n",
            "Vecinos de 'primo':  [('skate', 0.7230061195654247), ('hijo', 0.6495612619961113), ('hija', 0.47489409717704767), ('videojuegos', 0.4737924300299636), ('prima', 0.43367174171699674)]\n",
            "\n",
            "Vecinos de 'prima':  [('fotografia', 0.796570311070117), ('hija', 0.6594140714460223), ('hijo', 0.44078930388764637), ('jardineria', 0.4404314858706877), ('primo', 0.43367174171699674)]\n"
          ]
        }
      ],
      "source": [
        "S = cosine_similarity_matrix(PPMI) # Matriz de similitud coseno\n",
        "sim_df = pd.DataFrame(S, index=vocab, columns=vocab)\n",
        "\n",
        "targets = [\"abuelo\", \"abuela\", \"padre\", \"madre\", \"hijo\", \"hija\", \"tio\", \"tia\", \"primo\", \"prima\"]\n",
        "# Iterar sobre algunas palabras de interés y mostrar sus vecinos más cercanos\n",
        "for t in targets:\n",
        "    print(f\"\\nVecinos de '{t}': \")\n",
        "    for w,s in top_k_neighbors(t,vocab,S,k=5):\n",
        "        print(f\" {w:>12}\\t{s:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embeddings con SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "U, s, Vt = np.linalg.svd(PPMI, full_matrices=False)\n",
        "X2D= U[:,:2]* s[:2]  # Proyección 2D\n",
        "K = min(50, U.shape[1])   # #dims\n",
        "E = U[:, :K] * s[:K] # Embeddings\n",
        "\n",
        "words_to_plot = [\n",
        "    \"abuelo\", \"abuela\", \"padre\", \"madre\", \"hijo\", \"hija\",\n",
        "    \"tio\", \"tia\", \"primo\", \"prima\", \"sobrino\", \"sobrina\",\n",
        "    \"niño\", \"niña\", \"joven\", \"adulto\", \"mayor\",\n",
        "    \"juega\", \"pinta\", \"practica\", \"visita\",\n",
        "    \"casa\", \"sala\", \"jardin\", \"parque\", \"escuela\"\n",
        "]\n",
        "\n",
        "# Filtrar coordenadas y etiquetas para las palabras a graficar\n",
        "mask = [ w in words_to_plot for w in vocab]\n",
        "coords = X2D[mask]\n",
        "labels = [w for w in vocab if w in words_to_plot]\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(coords[:,0],coords[:,1])\n",
        "for (x,y),lab in zip(coords,labels):\n",
        "  plt.text(x+0.01,y+0.01,lab)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word_vec(word, vocab=vocab, E=E):\n",
        "    \"\"\"\n",
        "    Obtiene el vector de embedding para una palabra dada.\n",
        "    Args:\n",
        "        word (str): Palabra objetivo.\n",
        "        vocab (list): Lista de palabras en el vocabulario.\n",
        "        E (np.ndarray): Matriz de embeddings.\n",
        "    Returns:\n",
        "        np.ndarray or None: Vector de embedding o None si la palabra no está en el vocabulario.\n",
        "    \"\"\"\n",
        "    if word not in vocab:\n",
        "        return None\n",
        "    return E[vocab.index(word)]\n",
        "\n",
        "def most_similar(vec, E=E, topn=5, exclude_idx=None):\n",
        "    \"\"\"\n",
        "    Encuentra las palabras más similares a un vector dado usando similitud coseno.\n",
        "    Args:\n",
        "        vec (np.ndarray): Vector objetivo.\n",
        "        E (np.ndarray): Matriz de embeddings.\n",
        "        topn (int): Número de palabras similares a retornar.\n",
        "        exclude_idx (int or None): Índice a excluir de los resultados (por ejemplo, la palabra misma).\n",
        "    Returns:\n",
        "        tuple: (índices de palabras similares, similitudes)\n",
        "    \"\"\"\n",
        "    norms = np.linalg.norm(E, axis=1, keepdims=True) + 1e-12\n",
        "    En = E / norms\n",
        "    vn = vec / (np.linalg.norm(vec) + 1e-12)\n",
        "    sims = En @ vn\n",
        "    if exclude_idx is not None:\n",
        "        sims[exclude_idx] = -np.inf\n",
        "    idxs = np.argsort(-sims)[:topn]\n",
        "    return idxs, sims[idxs]\n",
        "\n",
        "def analogy(a, b, c, vocab=vocab, E=E, topn=5):\n",
        "    \"\"\"\n",
        "    Resuelve analogías del tipo \"a es a b como c es a ?\".\n",
        "    Args:\n",
        "        a (str): Primera palabra de la analogía.\n",
        "        b (str): Segunda palabra de la analogía.\n",
        "        c (str): Tercera palabra de la analogía.\n",
        "        vocab (list): Lista de palabras en el vocabulario.\n",
        "        E (np.ndarray): Matriz de embeddings.\n",
        "        topn (int): Número de resultados a retornar.\n",
        "    Returns:\n",
        "        list: Lista de tuplas (palabra, similitud) de las palabras que completan la analogía.\n",
        "    \"\"\"\n",
        "    va, vb, vc = word_vec(a, vocab, E), word_vec(b, vocab, E), word_vec(c, vocab, E)\n",
        "    if va is None or vb is None or vc is None:\n",
        "        return []\n",
        "    target = vb - va + vc\n",
        "    idxs, sims = most_similar(target, E=E, topn=topn + 3)\n",
        "    results = []\n",
        "    forbids = {vocab.index(w) for w in [a, b, c] if w in vocab}\n",
        "    for idx, score in zip(idxs, sims):\n",
        "        if idx not in forbids:\n",
        "            results.append((vocab[idx], float(score)))\n",
        "        if len(results) == topn:\n",
        "            break\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzRf6sNDiF1v"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Crear 10 analigias validas basadas en su texto, tome en cuenta que es necesario utilizar el codigo visto en clase y ajuste su corpus para poder lograr obtener todas las analogias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WUUiX7oBffZg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== RESULTADOS DE ANALOGÍAS (top-3) ====\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>analogia</th>\n",
              "      <th>esperado</th>\n",
              "      <th>top3</th>\n",
              "      <th>acierto_en_top3</th>\n",
              "      <th>posicion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abuelo:abuela::padre:?</td>\n",
              "      <td>madre</td>\n",
              "      <td>herramientas, autos, tio</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>padre:madre::hijo:?</td>\n",
              "      <td>hija</td>\n",
              "      <td>hija, tia, medicina</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tio:tia::sobrino:?</td>\n",
              "      <td>sobrina</td>\n",
              "      <td>danza, reuniones, madre</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>primo:prima::hijo:?</td>\n",
              "      <td>hija</td>\n",
              "      <td>fotografia, hija, pintura</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abuelo:mayor::sobrino:?</td>\n",
              "      <td>niño</td>\n",
              "      <td>con, casa, visita</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hijo:joven::hija:?</td>\n",
              "      <td>joven</td>\n",
              "      <td>con, practica, toma</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>padre:mecanica::hijo:?</td>\n",
              "      <td>skate</td>\n",
              "      <td>cuadros, pintura, fotografia</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>abuela:jardineria::hija:?</td>\n",
              "      <td>pintura</td>\n",
              "      <td>fotografia, prima, hijo</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tio:pesca::primo:?</td>\n",
              "      <td>videojuegos</td>\n",
              "      <td>skate, videojuegos, hijo</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tia:danza::prima:?</td>\n",
              "      <td>fotografia</td>\n",
              "      <td>fotografia, hija, jardineria</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    analogia     esperado                          top3  \\\n",
              "0     abuelo:abuela::padre:?        madre      herramientas, autos, tio   \n",
              "1        padre:madre::hijo:?         hija           hija, tia, medicina   \n",
              "2         tio:tia::sobrino:?      sobrina       danza, reuniones, madre   \n",
              "3        primo:prima::hijo:?         hija     fotografia, hija, pintura   \n",
              "4    abuelo:mayor::sobrino:?         niño             con, casa, visita   \n",
              "5         hijo:joven::hija:?        joven           con, practica, toma   \n",
              "6     padre:mecanica::hijo:?        skate  cuadros, pintura, fotografia   \n",
              "7  abuela:jardineria::hija:?      pintura       fotografia, prima, hijo   \n",
              "8         tio:pesca::primo:?  videojuegos      skate, videojuegos, hijo   \n",
              "9         tia:danza::prima:?   fotografia  fotografia, hija, jardineria   \n",
              "\n",
              "   acierto_en_top3  posicion  \n",
              "0            False       NaN  \n",
              "1             True       1.0  \n",
              "2            False       NaN  \n",
              "3             True       2.0  \n",
              "4            False       NaN  \n",
              "5            False       NaN  \n",
              "6            False       NaN  \n",
              "7            False       NaN  \n",
              "8             True       2.0  \n",
              "9             True       1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tests = [\n",
        "    # Género (parejas familiares)\n",
        "    (\"abuelo\", \"abuela\", \"padre\", \"madre\"),\n",
        "    (\"padre\", \"madre\", \"hijo\", \"hija\"),\n",
        "    (\"tio\", \"tia\", \"sobrino\", \"sobrina\"),\n",
        "    (\"primo\", \"prima\", \"hijo\", \"hija\"),\n",
        "    # Edades (mayor/adulto/joven/niño)\n",
        "    (\"abuelo\", \"mayor\", \"sobrino\", \"niño\"),\n",
        "    (\"hijo\", \"joven\", \"hija\", \"joven\"),  # mapea a atributo compartido\n",
        "    # Actividades (relaciones persona-actividad)\n",
        "    (\"padre\", \"mecanica\", \"hijo\", \"skate\"),\n",
        "    (\"abuela\", \"jardineria\", \"hija\", \"pintura\"),\n",
        "    (\"tio\", \"pesca\", \"primo\", \"videojuegos\"),\n",
        "    (\"tia\", \"danza\", \"prima\", \"fotografia\"),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for a, b, c, expected in tests:\n",
        "    preds = analogy(a, b, c, topn=5)\n",
        "    top3 = [w for w, _ in preds[:3]]\n",
        "    rank = next((i for i, w in enumerate(top3) if w == expected), None)\n",
        "    rows.append({\n",
        "        \"analogia\": f\"{a}:{b}::{c}:?\",\n",
        "        \"esperado\": expected,\n",
        "        \"top3\": \", \".join(top3),\n",
        "        \"acierto_en_top3\": rank is not None,\n",
        "        \"posicion\": (rank + 1 if rank is not None else None)\n",
        "    })\n",
        "\n",
        "df_analogias = pd.DataFrame(rows)\n",
        "print(\"\\n==== RESULTADOS DE ANALOGÍAS (top-3) ====\\n\")\n",
        "display(df_analogias)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp-lab4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
