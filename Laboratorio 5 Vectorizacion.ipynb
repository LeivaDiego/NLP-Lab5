{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXhjY9dGwJls"
      },
      "source": [
        "NOMBRES: Diego Alberto\n",
        "\n",
        "APELLIDOS: Leiva Pérez\n",
        "\n",
        "CARNE: 21752\n",
        "\n",
        "FECHA: 04/09/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilidades para Texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Convierte a minúsculas, elimina puntuación y caracteres especiales,\n",
        "    y normaliza espacios en blanco.\n",
        "    Args:\n",
        "        text (str): Texto a normalizar.\n",
        "    Returns:\n",
        "        str: Texto normalizado.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    # Conserva letras (incluye tildes/ñ), dígitos y espacios.\n",
        "    text = re.sub(r\"[^a-záéíóúüñ0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def tokenize(text: str):\n",
        "    \"\"\"\n",
        "    Tokeniza el texto normalizado en palabras.\n",
        "    Args:\n",
        "        text (str): Texto a tokenizar.\n",
        "    Returns:\n",
        "        list: Lista de tokens (palabras).\n",
        "    \"\"\"\n",
        "    return normalize_text(text).split()\n",
        "\n",
        "def build_vocab(tokenized_docs, min_freq: int = 1):\n",
        "    \"\"\"\n",
        "    Construye el vocabulario a partir de documentos tokenizados.\n",
        "    Args:\n",
        "        tokenized_docs (list): Lista de documentos tokenizados.\n",
        "        min_freq (int): Frecuencia mínima para incluir una palabra en el vocabulario.\n",
        "    Returns:\n",
        "        tuple: (vocabulario, word2idx, idx2word, counts)\n",
        "    \"\"\"\n",
        "    counts = Counter([t for doc in tokenized_docs for t in doc])\n",
        "    vocab = [w for w, c in counts.items() if c >= min_freq]\n",
        "    vocab = sorted(vocab)\n",
        "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "    idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "    return vocab, word2idx, idx2word, counts\n",
        "\n",
        "def sliding_windows_indices(center, window_size, n):\n",
        "    \"\"\"\n",
        "    Obtiene los índices de las palabras en una ventana deslizante alrededor de una palabra central.\n",
        "    Args:\n",
        "        center (int): Índice de la palabra central.\n",
        "        window_size (int): Tamaño de la ventana (número de palabras a cada lado).\n",
        "        n (int): Longitud total de la secuencia.\n",
        "    Returns:\n",
        "        list: Lista de índices en la ventana deslizante.\n",
        "    \"\"\"\n",
        "    start = max(0, center - window_size)\n",
        "    end = min(n, center + window_size + 1)\n",
        "    return [i for i in range(start, end) if i != center]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7nnvCPLh5Ms"
      },
      "source": [
        "## Ejercicio 1\n",
        "Cree un corpus a su gusto como el visto en clase, cálcule PPMI, pero aplicando Lapace Smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hf3GX1_liFXd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Docs: 20\n",
            "Vocab size: 68\n",
            "Top-10 más frecuentes: [('la', 30), ('el', 24), ('en', 16), ('y', 15), ('con', 13), ('joven', 13), ('mayor', 6), ('sala', 5), ('adulto', 5), ('adulta', 5)]\n"
          ]
        }
      ],
      "source": [
        "corpus_docs = [\n",
        "    # Abuelos/as y edad/actividad\n",
        "    \"el abuelo mayor juega ajedrez en la sala con la abuela mayor\",\n",
        "    \"la abuela mayor cuida el jardin y hace jardineria con el abuelo mayor\",\n",
        "    # Padres y madres + actividades\n",
        "    \"el padre adulto repara autos en el taller y aprende mecanica\",\n",
        "    \"la madre adulta estudia medicina y cuida la casa con paciencia\",\n",
        "    # Hijos/as + actividades/edad\n",
        "    \"el hijo joven practica skate en el parque despues de la escuela\",\n",
        "    \"la hija joven pinta cuadros y aprende pintura en la escuela\",\n",
        "    # Tios/as + actividades/edad\n",
        "    \"el tio adulto sale a pesca y conversa en la sala\",\n",
        "    \"la tia adulta baila danza y organiza reuniones en la casa\",\n",
        "    # Primos/as + actividades/edad\n",
        "    \"el primo joven juega videojuegos y estudia con el hijo joven\",\n",
        "    \"la prima joven hace fotografia y practica pintura con la hija joven\",\n",
        "    # Sobrinos/as + edad\n",
        "    \"el sobrino niño visita la casa y lee cuentos en la sala\",\n",
        "    \"la sobrina niña dibuja en el jardin y juega con la prima joven\",\n",
        "    # Conexiones cruzadas (refuerza co-ocurrencias)\n",
        "    \"el padre adulto conversa con el abuelo mayor en la sala\",\n",
        "    \"la madre adulta camina con la abuela mayor en el jardin\",\n",
        "    \"el tio adulto repara herramientas en el taller con el padre adulto\",\n",
        "    \"la tia adulta organiza danza en la escuela y ayuda a la madre adulta\",\n",
        "    \"el primo joven patina skate en el parque y habla con el sobrino niño\",\n",
        "    \"la prima joven toma fotografia en el jardin y pinta con la hija joven\",\n",
        "    \"el hijo joven visita la casa y estudia en la escuela con el primo joven\",\n",
        "    \"la hija joven practica pintura en la sala y conversa con la sobrina niña\",\n",
        "]\n",
        "\n",
        "# Preprocesamiento\n",
        "tokenized_docs = [tokenize(d) for d in corpus_docs] # Lista de listas de tokens\n",
        "vocab, word2idx, idx2word, counts = build_vocab(tokenized_docs, min_freq=1) # Vocabulario y mapeos\n",
        "\n",
        "# Estadísticas básicas\n",
        "print(\"Docs:\", len(tokenized_docs)) # Número de documentos\n",
        "print(\"Vocab size:\", len(vocab)) # Tamaño del vocabulario \n",
        "print(\"Top-10 más frecuentes:\", Counter([t for d in tokenized_docs for t in d]).most_common(10)) # Top-10 palabras más frecuentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzRf6sNDiF1v"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Crear 10 analigias validas basadas en su texto, tome en cuenta que es necesario utilizar el codigo visto en clase y ajuste su corpus para poder lograr obtener todas las analogias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUUiX7oBffZg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp-lab4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
